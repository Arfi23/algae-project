{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a95dc77-6786-4eb7-9458-702f78fa2d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# 1. Import Library dan Setup Environment\n",
    "# ===========================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Gunakan GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device yang digunakan:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c696af3-5826-4722-bdae-93483555b402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# 2. Fungsi Bantuan Umum\n",
    "# ===========================================\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    \"\"\"Menetapkan seed random agar hasil eksperimen bisa direplikasi\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "def visualize_tile(x_tile, y_true=None, y_pred=None, class_names=None, idx=0):\n",
    "    \"\"\"\n",
    "    Menampilkan citra tile beserta mask ground-truth dan prediksi\n",
    "    \"\"\"\n",
    "    if isinstance(x_tile, torch.Tensor):\n",
    "        x = x_tile.cpu().numpy()\n",
    "        x = np.transpose(x, (1,2,0))  # ubah dari [B,H,W] -> [H,W,B]\n",
    "    else:\n",
    "        x = x_tile\n",
    "\n",
    "    # menampilkan pseudo-RGB (karena data hyperspectral)\n",
    "    B = x.shape[2]\n",
    "    b1, b2, b3 = int(B*0.05), int(B*0.5), int(B*0.9)\n",
    "    rgb = x[..., [b1, b2, b3]]\n",
    "    rgb_norm = (rgb - rgb.min()) / (rgb.max() - rgb.min() + 1e-9)\n",
    "\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.subplot(1,3,1); plt.imshow(rgb_norm); plt.title(\"Citra (Pseudo-RGB)\")\n",
    "    if y_true is not None:\n",
    "        plt.subplot(1,3,2); plt.imshow(y_true, cmap='tab20'); plt.title(\"Ground Truth\")\n",
    "    if y_pred is not None:\n",
    "        plt.subplot(1,3,3); plt.imshow(y_pred, cmap='tab20'); plt.title(\"Prediksi\")\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0898bb81-a9a6-439b-a6f6-380a66272726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# 3. Dataset Loader (SeaweedDataset) dan Label Mapping\n",
    "# ====================================================\n",
    "\n",
    "def load_label_mapping(json_path):\n",
    "    \"\"\"Membaca file label_classes.json untuk mapping id ke nama kelas\"\"\"\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    idx_to_name = {i: item[\"name\"] for i, item in enumerate(data)}\n",
    "    return idx_to_name\n",
    "\n",
    "def normalize_reflectance(cube):\n",
    "    \"\"\"Menormalkan nilai reflektansi ke rentang 0-1\"\"\"\n",
    "    cube = np.nan_to_num(cube)\n",
    "    scaler = MinMaxScaler()\n",
    "    flat = cube.reshape(-1, cube.shape[-1])\n",
    "    flat_scaled = scaler.fit_transform(flat)\n",
    "    return flat_scaled.reshape(cube.shape)\n",
    "\n",
    "class SeaweedDataset(Dataset):\n",
    "    def __init__(self, data_files, label_map, tile_size=128):\n",
    "        self.data_files = data_files\n",
    "        self.label_map = label_map\n",
    "        self.tile_size = tile_size\n",
    "        self.tiles = []\n",
    "\n",
    "        for f in data_files:\n",
    "            data = np.load(f)\n",
    "            x = data[\"x\"]\n",
    "            y = data[\"y\"]\n",
    "            x = normalize_reflectance(x)\n",
    "            H, W, C = x.shape\n",
    "\n",
    "            # Membagi citra menjadi tile berukuran tile_size x tile_size\n",
    "            for i in range(0, H, tile_size):\n",
    "                for j in range(0, W, tile_size):\n",
    "                    x_tile = x[i:i+tile_size, j:j+tile_size, :]\n",
    "                    y_tile = y[i:i+tile_size, j:j+tile_size]\n",
    "                    if np.any(y_tile > 0):  # abaikan tile kosong\n",
    "                        self.tiles.append((x_tile, y_tile))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tiles)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_tile, y_tile = self.tiles[idx]\n",
    "        x_tile = torch.tensor(x_tile.transpose(2, 0, 1), dtype=torch.float32)\n",
    "        y_tile = torch.tensor(y_tile, dtype=torch.long)\n",
    "        return x_tile, y_tile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a8f3df-9e8e-434a-80fa-e38b615578bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# 4. Load Dataset dan Splitting\n",
    "# ===========================================\n",
    "\n",
    "data_dir = \"../data/processed\"  # lokasi data hasil preprocessing\n",
    "label_json_path = \"../data/annotation/segmentation_masks/label_classes.json\" # lokasi file label_classes.json\n",
    "\n",
    "label_map = load_label_mapping(label_json_path)\n",
    "print(f\"Jumlah total kelas: {len(label_map)}\")\n",
    "print(\"Contoh nama kelas:\", list(label_map.values())[:5])\n",
    "\n",
    "# Ambil semua file .npz hasil preprocessing\n",
    "all_files = sorted([os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith(\".npz\")])\n",
    "print(f\"\\nTotal file ditemukan: {len(all_files)}\")\n",
    "\n",
    "# Tampilkan label unik per file\n",
    "for f in all_files[:3]:\n",
    "    data = np.load(f)\n",
    "    mask = data[\"y\"]\n",
    "    unique_labels = np.unique(mask)\n",
    "    print(f\"{os.path.basename(f)} -> Label unik: {unique_labels}\")\n",
    "\n",
    "# Buat dataset dan dataloader\n",
    "dataset = SeaweedDataset(all_files, label_map, tile_size=128)\n",
    "\n",
    "# Split train-val 80%-20%\n",
    "n = len(dataset)\n",
    "idxs = list(range(n))\n",
    "random.shuffle(idxs)\n",
    "split = int(0.8 * n)\n",
    "train_idx, val_idx = idxs[:split], idxs[split:]\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=4, sampler=torch.utils.data.SubsetRandomSampler(train_idx))\n",
    "val_loader   = DataLoader(dataset, batch_size=4, sampler=torch.utils.data.SubsetRandomSampler(val_idx))\n",
    "\n",
    "num_classes = len(label_map)\n",
    "print(f\"\\nJumlah tile train: {len(train_idx)}, val: {len(val_idx)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82057837-2b53-467d-8fb5-508cdc66b4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================\n",
    "# 5. Model Fully Convolutional HybridSN (3D+2D CNN)\n",
    "# =================================================\n",
    "\n",
    "class FCHybridSN(nn.Module):\n",
    "    def __init__(self, in_bands=300, num_classes=41):\n",
    "        super().__init__()\n",
    "        self.conv3d_1 = nn.Conv3d(1, 16, (7,3,3), padding=(0,1,1))\n",
    "        self.bn3d_1 = nn.BatchNorm3d(16)\n",
    "        self.conv3d_2 = nn.Conv3d(16, 32, (5,3,3), padding=(0,1,1))\n",
    "        self.bn3d_2 = nn.BatchNorm3d(32)\n",
    "        self.conv3d_3 = nn.Conv3d(32, 64, (3,3,3), padding=(0,1,1))\n",
    "        self.bn3d_3 = nn.BatchNorm3d(64)\n",
    "\n",
    "        self._out_spec = in_bands - 12\n",
    "        mid_ch = 256\n",
    "        self.conv2d_1 = nn.Conv2d(64 * max(1, self._out_spec), mid_ch, 3, padding=1)\n",
    "        self.bn2d_1 = nn.BatchNorm2d(mid_ch)\n",
    "        self.conv2d_2 = nn.Conv2d(mid_ch, 128, 3, padding=1)\n",
    "        self.bn2d_2 = nn.BatchNorm2d(128)\n",
    "        self.conv2d_3 = nn.Conv2d(128, 64, 3, padding=1)\n",
    "        self.bn2d_3 = nn.BatchNorm2d(64)\n",
    "        self.classifier = nn.Conv2d(64, num_classes, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, Bands, H, W = x.shape\n",
    "        x3 = x.unsqueeze(1)\n",
    "        x3 = F.relu(self.bn3d_1(self.conv3d_1(x3)))\n",
    "        x3 = F.relu(self.bn3d_2(self.conv3d_2(x3)))\n",
    "        x3 = F.relu(self.bn3d_3(self.conv3d_3(x3)))\n",
    "        B, C3, out_spec, H, W = x3.shape\n",
    "        x2 = x3.view(B, C3 * out_spec, H, W)\n",
    "        x2 = F.relu(self.bn2d_1(self.conv2d_1(x2)))\n",
    "        x2 = F.relu(self.bn2d_2(self.conv2d_2(x2)))\n",
    "        x2 = F.relu(self.bn2d_3(self.conv2d_3(x2)))\n",
    "        return self.classifier(x2)\n",
    "\n",
    "model = FCHybridSN(in_bands=300, num_classes=num_classes).to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73b0701-198a-4987-8da8-2ee78970472c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# 6. Fungsi Training dan Evaluasi\n",
    "# ===========================================\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "def pixel_accuracy(pred, target):\n",
    "    valid = (target >= 0)\n",
    "    correct = (pred[valid] == target[valid]).sum()\n",
    "    total = valid.sum()\n",
    "    return (correct.float() / (total.float() + 1e-9)).item()\n",
    "\n",
    "def iou_per_class(pred, target, num_classes):\n",
    "    ious = []\n",
    "    for cls in range(num_classes):\n",
    "        pred_i = (pred == cls)\n",
    "        target_i = (target == cls)\n",
    "        inter = (pred_i & target_i).sum()\n",
    "        union = (pred_i | target_i).sum()\n",
    "        if union == 0:\n",
    "            ious.append(float('nan'))\n",
    "        else:\n",
    "            ious.append((inter.float() / union.float()).item())\n",
    "    return ious\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e619f6b-0bb7-4088-8458-deef4332bad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# 7. Loop Training Utama\n",
    "# ===========================================\n",
    "\n",
    "num_epochs = 20\n",
    "best_val_acc = 0.0\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "\n",
    "    # Validasi\n",
    "    model.eval()\n",
    "    val_accs, val_ious = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            preds = model(xb).argmax(dim=1)\n",
    "            val_accs.append(pixel_accuracy(preds, yb))\n",
    "            val_ious.extend(iou_per_class(preds, yb, num_classes))\n",
    "    mean_val_acc = np.nanmean(val_accs)\n",
    "    mean_iou = np.nanmean([v for v in val_ious if not np.isnan(v)])\n",
    "    print(f\"Epoch {epoch}/{num_epochs} | Loss={avg_loss:.4f} | ValAcc={mean_val_acc:.4f} | mIoU={mean_iou:.4f}\")\n",
    "\n",
    "    if mean_val_acc > best_val_acc:\n",
    "        best_val_acc = mean_val_acc\n",
    "        torch.save(model.state_dict(), \"hybridsn_seg_best.pth\")\n",
    "        print(\"OK, Model terbaik disimpan.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909596e5-5dad-49f9-a3d2-2fb43456d04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# 8. Visualisasi Hasil Prediksi\n",
    "# ===========================================\n",
    "\n",
    "model.load_state_dict(torch.load(\"hybridsn_seg_best.pth\"))\n",
    "model.eval()\n",
    "xb, yb = next(iter(val_loader))\n",
    "xb, yb = xb.to(device), yb.to(device)\n",
    "with torch.no_grad():\n",
    "    preds = model(xb).argmax(dim=1).cpu().numpy()\n",
    "yb_np = yb.cpu().numpy()\n",
    "visualize_tile(xb[0], y_true=yb_np[0], y_pred=preds[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48711db-7b33-4dec-9a0d-203178d8b1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# 9. Inferensi Citra Penuh\n",
    "# ===========================================\n",
    "\n",
    "def infer_full_image(model, cube, tile_size=128, stride=96):\n",
    "    model.eval()\n",
    "    H, W, B = cube.shape\n",
    "    out_logits = np.zeros((num_classes, H, W), dtype=np.float32)\n",
    "    count = np.zeros((H, W), dtype=np.float32)\n",
    "    for i in range(0, max(1, H - tile_size + 1), stride):\n",
    "        for j in range(0, max(1, W - tile_size + 1), stride):\n",
    "            tile = cube[i:i+tile_size, j:j+tile_size, :]\n",
    "            if tile.shape[0] < tile_size or tile.shape[1] < tile_size:\n",
    "                continue\n",
    "            x = torch.from_numpy(np.transpose(tile, (2,0,1))).unsqueeze(0).to(device).float()\n",
    "            with torch.no_grad():\n",
    "                probs = F.softmax(model(x), dim=1).cpu().numpy()[0]\n",
    "            out_logits[:, i:i+tile_size, j:j+tile_size] += probs\n",
    "            count[i:i+tile_size, j:j+tile_size] += 1\n",
    "    count[count==0] = 1.0\n",
    "    pred_map = (out_logits / count[np.newaxis,...]).argmax(axis=0)\n",
    "    return pred_map\n",
    "\n",
    "p = all_files[0]\n",
    "cube = np.load(p, allow_pickle=True)[\"x\"]\n",
    "predmap = infer_full_image(model, cube)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.imshow(predmap, cmap='tab20')\n",
    "plt.title(f\"Hasil Inferensi: {os.path.basename(p)}\")\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
